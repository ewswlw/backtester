{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import vectorbt as vbt\n",
    "import io\n",
    "import sys\n",
    "from contextlib import redirect_stdout\n",
    "from datetime import datetime\n",
    "import math\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple, List, Union, Optional\n",
    "from datetime import datetime\n",
    "from xbbg import blp\n",
    "\n",
    "# Define default mappings outside the class as constants\n",
    "DEFAULT_OHLC_MAPPING = {\n",
    "    ('I05510CA Index', 'INDEX_OAS_TSY_BP'): 'cad_oas',\n",
    "    ('LF98TRUU Index', 'INDEX_OAS_TSY_BP'): 'us_hy_oas',\n",
    "    ('LUACTRUU Index', 'INDEX_OAS_TSY_BP'): 'us_ig_oas',\n",
    "    ('SPTSX Index', 'PX_LAST'): 'tsx',\n",
    "    ('VIX Index', 'PX_LAST'): 'vix',\n",
    "    ('USYC3M30 Index', 'PX_LAST'): 'us_3m_10y',\n",
    "    ('BCMPUSGR Index', 'PX_LAST'): 'us_growth_surprises',\n",
    "    ('BCMPUSIF Index', 'PX_LAST'): 'us_inflation_surprises',\n",
    "    ('LEI YOY  Index', 'PX_LAST'): 'us_lei_yoy',\n",
    "    ('.HARDATA G Index', 'PX_LAST'): 'us_hard_data_surprises',\n",
    "    ('CGERGLOB Index', 'PX_LAST'): 'us_equity_revisions',\n",
    "    ('.ECONREGI G Index', 'PX_LAST'): 'us_economic_regime',\n",
    "}\n",
    "\n",
    "DEFAULT_ER_YTD_MAPPING = {\n",
    "    ('I05510CA Index', 'INDEX_EXCESS_RETURN_YTD'): 'cad_ig_er',\n",
    "    ('LF98TRUU Index', 'INDEX_EXCESS_RETURN_YTD'): 'us_hy_er',\n",
    "    ('LUACTRUU Index', 'INDEX_EXCESS_RETURN_YTD'): 'us_ig_er',\n",
    "}\n",
    "\n",
    "class DataFetcher:\n",
    "    def __init__(\n",
    "        self,\n",
    "        start_date: str = '2002-01-01',\n",
    "        end_date: str = None,\n",
    "        periodicity: str = 'D',\n",
    "        align_start: bool = True,\n",
    "        fill: str = 'ffill',\n",
    "        start_date_align: str = 'yes',\n",
    "        ohlc_mapping: Dict[Tuple[str, str], str] = None,\n",
    "        er_ytd_mapping: Dict[Tuple[str, str], str] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the DataFetcher class with all configuration parameters\n",
    "\n",
    "        Args:\n",
    "            start_date: Start date in YYYY-MM-DD format\n",
    "            end_date: End date in YYYY-MM-DD format (defaults to current date)\n",
    "            periodicity: Data frequency ('D' for daily)\n",
    "            align_start: Whether to align data from the start date\n",
    "            fill: Fill method ('ffill' for forward fill)\n",
    "            start_date_align: Whether to align start dates ('yes' or 'no')\n",
    "            ohlc_mapping: Custom mapping for price data (defaults to predefined mapping)\n",
    "            er_ytd_mapping: Custom mapping for excess return data (defaults to predefined mapping)\n",
    "        \"\"\"\n",
    "        # Set default end date to today if not provided\n",
    "        if end_date is None:\n",
    "            self.end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            self.end_date = end_date\n",
    "\n",
    "        # Store all parameters as instance attributes\n",
    "        self.start_date = start_date\n",
    "        self.periodicity = periodicity\n",
    "        self.align_start = align_start\n",
    "        self.fill = fill\n",
    "        self.start_date_align = start_date_align\n",
    "\n",
    "        # Use provided mappings or default to the ones defined outside the class\n",
    "        self.ohlc_mapping = ohlc_mapping if ohlc_mapping is not None else DEFAULT_OHLC_MAPPING\n",
    "        self.er_ytd_mapping = er_ytd_mapping if er_ytd_mapping is not None else DEFAULT_ER_YTD_MAPPING\n",
    "\n",
    "        # List of problematic dates that need cleaning\n",
    "        self.bad_dates = {\n",
    "            '2005-11-15': {'column': 'cad_oas', 'action': 'use_previous'}\n",
    "        }\n",
    "\n",
    "    def update_parameters(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Update any of the class parameters\n",
    "\n",
    "        Args:\n",
    "            **kwargs: Any parameter to update\n",
    "        \"\"\"\n",
    "        for key, value in kwargs.items():\n",
    "            if hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "            else:\n",
    "                raise AttributeError(f\"DataFetcher has no attribute '{key}'\")\n",
    "\n",
    "        # If end_date is updated to None, set it to current date\n",
    "        if 'end_date' in kwargs and kwargs['end_date'] is None:\n",
    "            self.end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    def fetch_bloomberg_data(self, mapping: Optional[Dict[Tuple[str, str], str]] = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fetch data from Bloomberg using xbbg using class parameters\n",
    "\n",
    "        Args:\n",
    "            mapping: Optional override for the mapping to use\n",
    "\n",
    "        Returns:\n",
    "            DataFrame with requested data\n",
    "        \"\"\"\n",
    "        # Use provided mapping or default to ohlc_mapping\n",
    "        mapping_to_use = mapping if mapping is not None else self.ohlc_mapping\n",
    "\n",
    "        securities = list(set(security for security, _ in mapping_to_use.keys()))\n",
    "        fields = list(set(field for _, field in mapping_to_use.keys()))\n",
    "\n",
    "        # Fetch data using xbbg\n",
    "        df = blp.bdh(\n",
    "            tickers=securities,\n",
    "            flds=fields,\n",
    "            start_date=self.start_date,\n",
    "            end_date=self.end_date,\n",
    "            Per=self.periodicity\n",
    "        )\n",
    "\n",
    "        # Create a new DataFrame with renamed columns\n",
    "        renamed_df = pd.DataFrame(index=df.index)\n",
    "        for (security, field), new_name in mapping_to_use.items():\n",
    "            if (security, field) in df.columns:\n",
    "                renamed_df[new_name] = df[(security, field)]\n",
    "\n",
    "        return renamed_df\n",
    "\n",
    "    def convert_er_ytd_to_index(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert excess return YTD data to an index, only for securities in er_ytd_mapping\n",
    "\n",
    "        Args:\n",
    "            df: DataFrame containing excess return YTD columns\n",
    "\n",
    "        Returns:\n",
    "            DataFrame with excess return columns converted to indices\n",
    "        \"\"\"\n",
    "        result = pd.DataFrame(index=df.index)\n",
    "\n",
    "        # Only convert columns that are in the er_ytd_mapping values\n",
    "        er_columns = list(self.er_ytd_mapping.values())\n",
    "        for column in df.columns:\n",
    "            if column in er_columns:\n",
    "                # Convert YTD returns to daily returns\n",
    "                daily_returns = df[column].diff()\n",
    "\n",
    "                # Create index starting at 100\n",
    "                index_values = (1 + daily_returns / 100).cumprod() * 100\n",
    "                result[f\"{column}_index\"] = index_values\n",
    "\n",
    "        return result\n",
    "\n",
    "    def merge_dfs(self, df1: pd.DataFrame, df2: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Merge two DataFrames with proper date alignment and filling using class parameters\n",
    "\n",
    "        Args:\n",
    "            df1: First DataFrame\n",
    "            df2: Second DataFrame\n",
    "\n",
    "        Returns:\n",
    "            Merged DataFrame\n",
    "        \"\"\"\n",
    "        # Merge DataFrames\n",
    "        merged = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "        # Fill missing values\n",
    "        if self.fill:\n",
    "            merged = merged.fillna(method=self.fill)\n",
    "\n",
    "        return merged\n",
    "\n",
    "    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Clean specific known data issues defined in bad_dates\n",
    "\n",
    "        Args:\n",
    "            df: DataFrame to clean\n",
    "\n",
    "        Returns:\n",
    "            Cleaned DataFrame\n",
    "        \"\"\"\n",
    "        # Make a copy to avoid modification warnings\n",
    "        cleaned_df = df.copy()\n",
    "\n",
    "        # Process each bad date according to defined actions\n",
    "        for date, info in self.bad_dates.items():\n",
    "            if date in cleaned_df.index and info['column'] in cleaned_df.columns:\n",
    "                if info['action'] == 'use_previous':\n",
    "                    prev_value = cleaned_df.loc[cleaned_df.index < date, info['column']].iloc[-1]\n",
    "                    cleaned_df.loc[date, info['column']] = prev_value\n",
    "\n",
    "        return cleaned_df\n",
    "\n",
    "    def get_full_dataset(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get a complete dataset with both price data and excess return indices using class parameters.\n",
    "        If start_date_align is 'yes', will find the first date where all data is available.\n",
    "\n",
    "        Returns:\n",
    "            Complete DataFrame with all requested data\n",
    "        \"\"\"\n",
    "        # Fetch the main price data\n",
    "        df_ohlc = self.fetch_bloomberg_data(mapping=self.ohlc_mapping)\n",
    "\n",
    "        # Fetch the excess return YTD data\n",
    "        er_ytd_df = self.fetch_bloomberg_data(mapping=self.er_ytd_mapping)\n",
    "\n",
    "        # Convert excess return YTD to index (only for columns in er_ytd_mapping)\n",
    "        er_index_df = self.convert_er_ytd_to_index(er_ytd_df)\n",
    "\n",
    "        # Merge all the datasets\n",
    "        final_df = self.merge_dfs(df_ohlc, er_index_df)\n",
    "\n",
    "        # Clean any known data issues\n",
    "        final_df = self.clean_data(final_df)\n",
    "\n",
    "        # If start_date_align is 'yes', keep only rows where all data is available\n",
    "        if self.start_date_align == 'yes':\n",
    "            # Find the first date with no NaN values\n",
    "            non_null_df = final_df.dropna(how='any')\n",
    "            if not non_null_df.empty:\n",
    "                first_complete_date = non_null_df.index[0]\n",
    "                # Filter to only include dates on or after the first complete date\n",
    "                final_df = final_df[final_df.index >= first_complete_date]\n",
    "\n",
    "        # Apply any final fill operations specified\n",
    "        if self.fill:\n",
    "            final_df = final_df.fillna(method=self.fill)\n",
    "\n",
    "        return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1565 entries, 2010-01-31 to 2015-12-31\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   cad_oas                 1565 non-null   float64\n",
      " 1   us_hy_oas               1565 non-null   float64\n",
      " 2   us_ig_oas               1565 non-null   float64\n",
      " 3   tsx                     1565 non-null   float64\n",
      " 4   vix                     1565 non-null   float64\n",
      " 5   us_3m_10y               1565 non-null   float64\n",
      " 6   us_growth_surprises     1565 non-null   float64\n",
      " 7   us_inflation_surprises  1565 non-null   float64\n",
      " 8   us_lei_yoy              1565 non-null   float64\n",
      " 9   us_hard_data_surprises  1565 non-null   float64\n",
      " 10  us_equity_revisions     1565 non-null   float64\n",
      " 11  us_economic_regime      1565 non-null   float64\n",
      " 12  cad_ig_er_index         1565 non-null   float64\n",
      " 13  us_hy_er_index          1565 non-null   float64\n",
      " 14  us_ig_er_index          1565 non-null   float64\n",
      "dtypes: float64(15)\n",
      "memory usage: 195.6+ KB\n",
      "None\n",
      "Date range: 2010-01-31 to 2015-12-31\n"
     ]
    }
   ],
   "source": [
    "# Test with a specific date range\n",
    "data_fetcher = DataFetcher(\n",
    "    start_date='2010-01-01',\n",
    "    end_date='2015-12-31',\n",
    "    start_date_align='yes'\n",
    ")\n",
    "date_range_df = data_fetcher.get_full_dataset()\n",
    "print(date_range_df.info())\n",
    "print(f\"Date range: {date_range_df.index.min()} to {date_range_df.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 530 entries, 2020-01-01 to 2021-12-31\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   cad_oas                 529 non-null    float64\n",
      " 1   us_hy_oas               529 non-null    float64\n",
      " 2   us_ig_oas               529 non-null    float64\n",
      " 3   tsx                     529 non-null    float64\n",
      " 4   vix                     529 non-null    float64\n",
      " 5   us_3m_10y               530 non-null    float64\n",
      " 6   us_growth_surprises     530 non-null    float64\n",
      " 7   us_inflation_surprises  530 non-null    float64\n",
      " 8   us_lei_yoy              508 non-null    float64\n",
      " 9   us_hard_data_surprises  519 non-null    float64\n",
      " 10  us_equity_revisions     528 non-null    float64\n",
      " 11  us_economic_regime      508 non-null    float64\n",
      " 12  cad_ig_er_index         528 non-null    float64\n",
      " 13  us_hy_er_index          528 non-null    float64\n",
      " 14  us_ig_er_index          528 non-null    float64\n",
      "dtypes: float64(15)\n",
      "memory usage: 82.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create with default parameters then update\n",
    "data_fetcher = DataFetcher()\n",
    "data_fetcher.update_parameters(\n",
    "    start_date='2020-01-01',\n",
    "    end_date='2021-12-31',\n",
    "    start_date_align='no'\n",
    ")\n",
    "updated_df = data_fetcher.get_full_dataset()\n",
    "print(updated_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tajana-fAeqvWeF-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
